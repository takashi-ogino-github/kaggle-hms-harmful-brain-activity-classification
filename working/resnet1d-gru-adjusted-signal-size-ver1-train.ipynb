{"cells":[{"cell_type":"markdown","metadata":{"papermill":{"duration":0.010616,"end_time":"2024-02-20T13:39:08.483737","exception":false,"start_time":"2024-02-20T13:39:08.473121","status":"completed"},"tags":[]},"source":["# Descripion\n","\n","本notebookは、[HMS Resnet1D-GRU Train notebook by Med Ali Bouchhioua](https://www.kaggle.com/code/medali1992/hms-resnet1d-gru-train?scriptVersionId=163575181)をベースにしたnotebookをさらにベースにした。\n","\n","## Changes 1 [LB:0.40]:\n","- [3,5,7,9,11]の畳み込みカーネル\n","- 損失関数: Hardswish  SiLU\n","- オプティマイザ: Adan -> AdamW\n","- 最小0.5Hzのバンドパスフィルター\n","- Total Evaluator: 最初のデータセットでは0 ～ 5, 2番目のデータセットで6 ～最大 が使用される\n","- データ拡張ライブラリAlbumentations: 10 ～ 25 Hz の範囲のバンドパス フィルターでランダムな周波数をカット\n","- 2 ステージの 20 エポック\n","\n","## Changes 2 [LB:0.38]:\n","- フィルターの次数が 6 から 2 に変更\n","    - 次数について、次数の6は、急激なジャンプがある場合に信号に非常に強い影響\n","- ハイカットオフ周波数が 25 Hz から 20 Hz に変更\n","\n","## Changes 3 [LB:0.38]:\n","- アノテーターの合計について [0..2]、[3..5]、[6..1000] の 3 つの部分に分ける\n","\n","## Changes 4 [LB:0.40]:\n","- アノテーターの合計について、[0..5]、[6..1000] の 2 つの部分に分ける\n","- [Med Ali Bouchhioua](https://www.kaggle.com/code/konstantinboyko/hms-resnet1d-gru-v22-human-6-train/comments#2681934) のアドバイスに従って、正則化値 0.166666667 を削除\n","- stage/fold セクションだけでなく、逆fold/stage セクションでもモデルをトレーニングできるコードを追加\n","- フィルタパラメータを追加\n","\n","## Changes 5 [LB:0.39]:\n","- データ拡張ライブラリAlbumentations: 信号全体を誤って見逃す\n","\n","## Changes 6 [LB:0.38]\n","- 信号サイズを半分に縮小し、信号全体からランダムに選択\n","\n","## Changes 7 [LB:0.36]\n","- 信号サイズを5分の1に縮小し、信号全体からランダムに選択\n","\n","## Changes 8 [LB:0.39]\n","- アノテーターの合計が [5..Max] の範囲にある 1ステージモデル\n","\n","## Changes 9 [LB:0.38]\n","- 信号サイズを5分の1に縮小し、信号全体からランダムに選択\n","- アノテーターの合計: [2..2 + 6..28]\n","\n","## Changes 10 [LB:]\n","- 信号のランダムな一般反転\n","- 信号のランダムな上下反転\n","\n","## Changes 11 [LB:0.37]\n","- 鑑定者の合計は[1..2 + 4..5]、[6..28]の2つの部分に分かれています。\n","\n","## Changes 12 [LB:]\n","- 鑑定者の合計は[1..5 -4(GPD)]、[6..28]の2つの部分に分かれています。\n","\n","## [Final Dataset](https://www.kaggle.com/datasets/konstantinboyko/hms-resnet1d-gru-weights-v82)\n","\n","## [Previous Train](https://www.kaggle.com/code/konstantinboyko/hms-resnet1d-gru-v33-human-5-stage-1-train)\n","\n","## [Inference Notebook for 82nd Dataset](https://www.kaggle.com/code/konstantinboyko/hms-resnet1d-gru-inference-1-5-dataset)\n","\n","\n","# Library"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T13:39:08.506622Z","iopub.status.busy":"2024-02-20T13:39:08.506265Z","iopub.status.idle":"2024-02-20T13:39:22.390307Z","shell.execute_reply":"2024-02-20T13:39:22.389312Z"},"papermill":{"duration":13.898864,"end_time":"2024-02-20T13:39:22.393405","exception":false,"start_time":"2024-02-20T13:39:08.494541","status":"completed"},"tags":[]},"outputs":[],"source":["import os\n","import gc\n","import sys\n","import math\n","import time\n","import random\n","import datetime as dt\n","import numpy as np\n","import pandas as pd\n","import wandb\n","\n","from glob import glob\n","from pathlib import Path\n","from typing import Dict, List, Union\n","import scipy.signal as scisig\n","from scipy.signal import butter, lfilter, freqz\n","from matplotlib import pyplot as plt\n","from tqdm.auto import tqdm\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD, AdamW\n","from torch.utils.data import DataLoader, Dataset\n","from torch.optim.lr_scheduler import (\n","    ReduceLROnPlateau,\n","    OneCycleLR,\n","    CosineAnnealingLR,\n","    CosineAnnealingWarmRestarts,\n",")\n","from torch.optim.optimizer import Optimizer\n","from sklearn.model_selection import GroupKFold\n","\n","#import cupy as cp\n","#import cupyx.scipy.signal as cpsig\n","\n","sys.path.append(\"/kaggle/input/kaggle-kl-div\")\n","import kaggle_kl_div\n","\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","device = torch.device(\"cuda\")\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n","\n","!cat /etc/os-release | grep -oP \"PRETTY_NAME=\\\"\\K([^\\\"]*)\"\n","print(f\"BUILD_DATE={os.environ['BUILD_DATE']}, CONTAINER_NAME={os.environ['CONTAINER_NAME']}\")\n","\n","try:\n","    print(\n","        f\"PyTorch Version:{torch.__version__}, CUDA is available:{torch.cuda.is_available()}, Version CUDA:{torch.version.cuda}\"\n","    )\n","    print(\n","        f\"Device Capability:{torch.cuda.get_device_capability()}, {torch.cuda.get_arch_list()}\"\n","    )\n","    print(\n","        f\"CuDNN Enabled:{torch.backends.cudnn.enabled}, Version:{torch.backends.cudnn.version()}\"\n","    )\n","except Exception:\n","    pass"]},{"cell_type":"markdown","metadata":{},"source":["# Directory settings"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class APP:\n","    jupyter = \"ipykernel\" in globals()\n","    if not jupyter:\n","        try:\n","            if \"IPython\" in globals().get(\"__doc__\", \"\"):\n","                jupyter = True\n","        except Exception as inst:\n","            print(inst)\n","\n","    kaggle = os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\", \"\") != \"\"\n","    local = os.environ.get(\"DOCKER_USING\", \"\") == \"LOCAL\"\n","    date_time_start = dt.datetime.now()\n","    dt_start_ymd_hms = date_time_start.strftime(\"%Y.%m.%d_%H-%M-%S\")\n","\n","    file_run_path = \"\"\n","    if jupyter:\n","        try:\n","            file_run_path = Path(globals().get(\"__vsc_ipynb_file__\", \"\"))\n","        except Exception as inst:\n","            print(inst)\n","\n","    else:\n","        try:\n","            file_run_path = Path(__file__)\n","        except Exception as inst:\n","            print(inst)\n","\n","    file_run_name = file_run_path.stem\n","    path_app = file_run_path.parent\n","    path_run = Path(os.getcwd())\n","    path_out = (\n","        Path(\"/kaggle/working\")\n","        if kaggle\n","        else file_run_path / f\"{file_run_name}_{dt_start_ymd_hms}\"\n","    )\n","\n","\n","OUTPUT_DIR = \"./\"\n","if not os.path.exists(OUTPUT_DIR):\n","    os.makedirs(OUTPUT_DIR)\n","\n","print(f\"jupyter:{APP.jupyter}, kaggle:{APP.kaggle}, local:{APP.local}\")\n","print(APP.file_run_path)\n","print(APP.path_out)"]},{"cell_type":"markdown","metadata":{},"source":["# Config"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T13:39:22.422Z","iopub.status.busy":"2024-02-20T13:39:22.421506Z","iopub.status.idle":"2024-02-20T13:39:22.433686Z","shell.execute_reply":"2024-02-20T13:39:22.432464Z"},"papermill":{"duration":0.029582,"end_time":"2024-02-20T13:39:22.435956","exception":false,"start_time":"2024-02-20T13:39:22.406374","status":"completed"},"tags":[]},"outputs":[],"source":["class CFG:\n","    VERSION = '1'\n","\n","    wandb = False\n","    debug = False\n","    create_eegs = False\n","    apex = True\n","    visualize = False\n","    save_all_models = True\n","\n","    # リソースの設定\n","    if debug:\n","        num_workers = 0\n","        parallel = False\n","    else:\n","        num_workers = os.cpu_count()\n","        parallel = True\n","\n","    # モデル学習の設定\n","    model_name = \"resnet1d_gru\"\n","    # optimizer = \"Adan\"\n","    optimizer = \"AdamW\"\n","    # 学習のハイパラメータ\n","    factor = 0.9\n","    eps = 1e-6\n","    lr = 8e-3\n","    min_lr = 1e-6\n","    batch_size = 64\n","    batch_koef_valid = 2\n","    batch_scheduler = True\n","    weight_decay = 1e-2\n","    gradient_accumulation_steps = 1\n","    max_grad_norm = 1e7\n","\n","    fixed_kernel_size = 5\n","\n","    # linear_layer_features = 424\n","    # kernels = [3, 5, 7, 9]\n","    #linear_layer_features = 448  # Full Signal = 10_000\n","    #linear_layer_features = 352  # Half Signal = 5_000\n","    linear_layer_features = 304   # 1/4, 1/5, 1/6  Signal = 2_000\n","    #linear_layer_features = 280  # 1/10  Signal = 1_000\n","    # linear_layer_features = 1000\n","\n","    kernels = [3, 5, 7, 9, 11]\n","    # kernels = [5, 7, 9, 11, 13]\n","\n","    seq_length = 50  # Second's\n","    sampling_rate = 200  # Hz\n","    nsamples = seq_length * sampling_rate  # サンプル数 10_000\n","    n_split_samples = 5\n","    out_samples = nsamples // n_split_samples  # 2_000\n","    sample_delta = nsamples - out_samples  # 8_000\n","    sample_offset = sample_delta // 2\n","    multi_validation = False\n","\n","    # 2-stageの設定\n","    train_by_stages = True\n","    train_by_folds = False\n","\n","    # 'GPD', 'GRDA', 'LPD', 'LRDA', 'Other', 'Seizure'\n","    n_stages = 2\n","    match n_stages:\n","        # case 1:\n","        #     train_stages = [0]\n","        #     epochs = [100]\n","        #     test_total_eval = 2\n","        #     total_evals_old = [[(2, 3), (6, 29)]]  # Deprecated\n","        #     total_evaluators = [ \n","        #         [   \n","        #             {'band':(2, 2), 'excl_evals':[]}, \n","        #             {'band':(6, 28), 'excl_evals':[]},\n","        #         ], \n","        #     ]            \n","        case 2:\n","            train_stages = [0, 1]\n","            epochs = [2, 4]\n","            test_total_eval = 0\n","            total_evaluators = [ \n","                [   \n","                    {'band':(0, 9), 'excl_evals':[]},\n","                ], \n","                [   \n","                    {'band':(10, 10000), 'excl_evals':[]}, \n","                ], \n","            ]            \n","        # case 3:\n","        #     train_stages = [0, 1, 2]\n","        #     epochs = [20, 50, 100]\n","        #     test_total_eval = 0\n","        #     total_evals_old = [(0, 3), (3, 6), (6, 29)]  # Deprecated\n","        #     total_evaluators = [ \n","        #         [   \n","        #             {'band':(0, 2), 'excl_evals':[]}, \n","        #         ], \n","        #         [   \n","        #             {'band':(3, 5), 'excl_evals':[]}, \n","        #         ], \n","        #         [   \n","        #             {'band':(6, 28), 'excl_evals':[]},\n","        #         ], \n","        #     ]            \n","    \n","    n_fold = 5\n","    train_folds = [0, 1, 2, 3, 4]\n","    # train_folds = [0]\n","\n","    patience = 11\n","    seed = 2024\n","\n","    bandpass_filter = {\"low\": 0.5, \"high\": 20, \"order\": 2}\n","    rand_filter = {\"probab\": 0.1, \"low\": 10, \"high\": 20, \"band\": 1.0, \"order\": 2}\n","    freq_channels = []  # [(8.0, 12.0)]; [(0.5, 4.5)]\n","    filter_order = 2\n","\n","    random_divide_signal = 0.05\n","    random_close_zone = 0.05\n","    random_common_negative_signal = 0.0\n","    random_common_reverse_signal = 0.0\n","    random_negative_signal = 0.05\n","    random_reverse_signal = 0.05\n","\n","    log_step = 100  # ワークアウト表示ステップ\n","    log_show = False\n","\n","    scheduler = \"CosineAnnealingWarmRestarts\"  # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts','OneCycleLR']\n","\n","    # CosineAnnealingLR params\n","    cosanneal_params = {\n","        \"T_max\": 6,\n","        \"eta_min\": 1e-5,\n","        \"last_epoch\": -1,\n","    }\n","\n","    # ReduceLROnPlateau params\n","    reduce_params = {\n","        \"mode\": \"min\",\n","        \"factor\": 0.2,\n","        \"patience\": 4,\n","        \"eps\": 1e-6,\n","        \"verbose\": True,\n","    }\n","\n","    # CosineAnnealingWarmRestarts params\n","    cosanneal_res_params = {\n","        \"T_0\": 20,\n","        \"eta_min\": 1e-6,\n","        \"T_mult\": 1,\n","        \"last_epoch\": -1,\n","    }\n","\n","    target_cols = [\n","        \"seizure_vote\",\n","        \"lpd_vote\",\n","        \"gpd_vote\",\n","        \"lrda_vote\",\n","        \"grda_vote\",\n","        \"other_vote\",\n","    ]\n","\n","    pred_cols = [x + \"_pred\" for x in target_cols]\n","\n","    map_features = [\n","        (\"Fp1\", \"T3\"),\n","        (\"T3\", \"O1\"),\n","        (\"Fp1\", \"C3\"),\n","        (\"C3\", \"O1\"),\n","        (\"Fp2\", \"C4\"),\n","        (\"C4\", \"O2\"),\n","        (\"Fp2\", \"T4\"),\n","        (\"T4\", \"O2\"),\n","        #('Fz', 'Cz'), ('Cz', 'Pz'),\n","    ]\n","\n","    eeg_features = [\"Fp1\", \"T3\", \"C3\", \"O1\", \"Fp2\", \"C4\", \"T4\", \"O2\"]  # 'Fz', 'Cz', 'Pz'\n","        # 'F3', 'P3', 'F7', 'T5', 'Fz', 'Cz', 'Pz', 'F4', 'P4', 'F8', 'T6', 'EKG']\n","    feature_to_index = {x: y for x, y in zip(eeg_features, range(len(eeg_features)))}\n","    simple_features = []  # 'Fz', 'Cz', 'Pz', 'EKG'\n","\n","    # eeg_features = [row for row in feature_to_index]\n","    # eeg_feat_size = len(eeg_features)\n","    \n","    n_map_features = len(map_features)\n","    in_channels = n_map_features + n_map_features * len(freq_channels) + len(simple_features)\n","    target_size = len(target_cols)\n","\n","    # PATHに関する設定\n","    # path_inp = Path(\"/kaggle/input\")\n","    path_inp = Path(\"../input\")\n","    path_src = path_inp / \"hms-harmful-brain-activity-classification/\"\n","    file_train = path_src / \"train.csv\"\n","    path_train = path_src / \"train_eegs\"\n","    file_features_test = path_train / \"100261680.parquet\"\n","    file_eeg_specs = path_inp / \"eeg-spectrogram-by-lead-id-unique/eeg_specs.npy\"   # eegから作ったspectrogram\n","    file_raw_eeg = path_inp / \"brain-eegs/eegs.npy\"                                 # 生のeeg\n","    #file_raw_eeg = path_inp / \"brain-eegs-plus/eegs.npy\"\n","    #file_raw_eeg = path_inp / \"brain-eegs-full/eegs.npy\"\n","\n","    if APP.kaggle:\n","        num_workers = 2\n","        parallel = True\n","        # GPU_DEVICES = \"auto\"\n","\n","\n","# print(CFG.eeg_feat_size, CFG.in_channels)\n","print(CFG.feature_to_index)\n","print(CFG.eeg_features)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.012027,"end_time":"2024-02-20T13:39:22.461399","exception":false,"start_time":"2024-02-20T13:39:22.449372","status":"completed"},"tags":[]},"source":["# Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T13:39:22.487641Z","iopub.status.busy":"2024-02-20T13:39:22.487254Z","iopub.status.idle":"2024-02-20T13:39:22.516856Z","shell.execute_reply":"2024-02-20T13:39:22.516021Z"},"papermill":{"duration":0.045586,"end_time":"2024-02-20T13:39:22.519244","exception":false,"start_time":"2024-02-20T13:39:22.473658","status":"completed"},"tags":[]},"outputs":[],"source":["def init_logger(log_file=OUTPUT_DIR + \"train.log\"):\n","    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n","\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=log_file)\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","\n","LOGGER = init_logger()\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return \"%dm %ds\" % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n","\n","\n","def quantize_data(data, classes):\n","    mu_x = mu_law_encoding(data, classes)\n","    return mu_x  # quantized\n","\n","\n","def mu_law_encoding(data, mu):\n","    mu_x = np.sign(data) * np.log(1 + mu * np.abs(data)) / np.log(mu + 1)\n","    return mu_x\n","\n","\n","def mu_law_expansion(data, mu):\n","    s = np.sign(data) * (np.exp(np.abs(data) * np.log(mu + 1)) - 1) / mu\n","    return s\n","\n","\n","def butter_bandpass(lowcut, highcut, fs, order=5):\n","    return butter(order, [lowcut, highcut], fs=fs, btype=\"band\")\n","\n","\n","def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n","    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n","    y = lfilter(b, a, data)\n","    return y\n","\n","\n","def butter_lowpass_filter(\n","    data, cutoff_freq=20, sampling_rate=CFG.sampling_rate, order=4\n","):\n","    nyquist = 0.5 * sampling_rate\n","    normal_cutoff = cutoff_freq / nyquist\n","    b, a = butter(order, normal_cutoff, btype=\"low\", analog=False)\n","    filtered_data = lfilter(b, a, data, axis=0)\n","    return filtered_data\n","\n","\n","def denoise_filter(x):\n","    # サンプリング周波数と希望のカットオフ周波数 (Hz 単位)。\n","     # ノイズの多い信号をフィルタリングして除去する\n","    y = butter_bandpass_filter(x, CFG.lowcut, CFG.highcut, CFG.sampling_rate, order=6)\n","    y = (y + np.roll(y, -1) + np.roll(y, -2) + np.roll(y, -3)) / 4\n","    y = y[0:-1:4]\n","    return y"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.011709,"end_time":"2024-02-20T13:40:46.512143","exception":false,"start_time":"2024-02-20T13:40:46.500434","status":"completed"},"tags":[]},"source":["# Parquet to EEG Signals Numpy Processing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T13:40:46.538575Z","iopub.status.busy":"2024-02-20T13:40:46.537913Z","iopub.status.idle":"2024-02-20T13:40:46.548666Z","shell.execute_reply":"2024-02-20T13:40:46.547909Z"},"papermill":{"duration":0.026463,"end_time":"2024-02-20T13:40:46.550473","exception":false,"start_time":"2024-02-20T13:40:46.52401","status":"completed"},"tags":[]},"outputs":[],"source":["def eeg_from_parquet(\n","    parquet_path: str, display: bool = False, seq_length=CFG.seq_length\n",") -> np.ndarray:\n","    \"\"\"\n","    この関数はparquetファイルを読み取り、読み取り値の中央の 50 秒を抽出します。\n","    次に、NaNを無視した平均値でNaN 値を埋めます\n","    @Args:\n","     :param parquet_path: 寄木細工ファイルへのパス。\n","     :param display: EEG プロットを表示するかどうか。\n","    @Returs:\n","     :return  np.array (time_steps, eeg_features) -> (10_000, 8)\n","    \"\"\"\n","\n","    # === 中央の50秒を取得する ===\n","    # 読み込み\n","    eeg = pd.read_parquet(parquet_path, columns=CFG.eeg_features)\n","    rows = len(eeg)\n","\n","    # 中央を切り取るためのデータの開始オフセット\n","    offset = (rows - CFG.nsamples) // 2\n","\n","    # 平均 50 秒、左右で同じ数の読み取り値がある\n","    eeg = eeg.iloc[offset : offset + CFG.nsamples]\n","\n","    if display:\n","        plt.figure(figsize=(10, 5))\n","        offset = 0\n","\n","    # === NumPyに変換 ===\n","\n","    # 同じサイズ（行×列）のゼロで初期化されたNumPy配列\n","    data = np.zeros((CFG.nsamples, len(CFG.eeg_features)))\n","\n","    for index, feature in enumerate(CFG.eeg_features):\n","        x = eeg[feature].values.astype(\"float32\")   # float32に変換\n","\n","        # NaNを無視した、指定した軸方向の平均を計算\n","        mean = np.nanmean(x)\n","        nan_percentage = np.isnan(x).mean()  # 特徴量内のNaNの割合\n","\n","        # Nan 値を埋める\n","        # NaN を要素ごとにチェックし、結果を論理配列として返します。\n","        if nan_percentage < 1:  # 一部の値が Nan であるが、すべてが Nan ではない場合\n","            x = np.nan_to_num(x, nan=mean)\n","        else:  # すべての値がNanの場合\n","            x[:] = 0\n","        data[:, index] = x\n","\n","        if display:\n","            if index != 0:\n","                offset += x.max()\n","            plt.plot(range(CFG.nsamples), x - offset, label=feature)\n","            offset -= x.min()\n","\n","    if display:\n","        plt.legend()\n","        name = parquet_path.split(\"/\")[-1].split(\".\")[0]\n","        plt.yticks([])\n","        plt.title(f\"EEG {name}\", size=16)\n","        plt.show()\n","\n","    return data"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.014802,"end_time":"2024-02-20T13:42:17.914507","exception":false,"start_time":"2024-02-20T13:42:17.899705","status":"completed"},"tags":[]},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T13:42:17.943814Z","iopub.status.busy":"2024-02-20T13:42:17.943506Z","iopub.status.idle":"2024-02-20T13:42:17.962159Z","shell.execute_reply":"2024-02-20T13:42:17.961453Z"},"papermill":{"duration":0.0354,"end_time":"2024-02-20T13:42:17.964068","exception":false,"start_time":"2024-02-20T13:42:17.928668","status":"completed"},"tags":[]},"outputs":[],"source":["class EEGDataset(Dataset):\n","    def __init__(\n","        self,\n","        df: pd.DataFrame,\n","        batch_size: int,\n","        eegs: Dict[int, np.ndarray],\n","        mode: str = \"train\",\n","        downsample: int = None,\n","        bandpass_filter: Dict[str, Union[int, float]] = None,\n","        rand_filter: Dict[str, Union[int, float]] = None,\n","    ):\n","        self.df = df\n","        self.batch_size = batch_size\n","        self.mode = mode\n","        self.eegs = eegs\n","        self.downsample = downsample\n","        self.offset = None\n","        self.bandpass_filter = bandpass_filter\n","        self.rand_filter = rand_filter\n","        \n","    def __len__(self):\n","        \"\"\"\n","        Length of dataset.\n","        \"\"\"\n","        # エポックあたりのパケット数を示します\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","        \"\"\"\n","        Get one item.\n","        \"\"\"\n","        # 1つのデータパケットを生成する\n","        X, y_prob = self.__data_generation(index)\n","        if self.downsample is not None:\n","            X = X[:: self.downsample, :]\n","        output = {\n","            \"eeg\": torch.tensor(X, dtype=torch.float32),\n","            \"labels\": torch.tensor(y_prob, dtype=torch.float32),\n","        }\n","        return output\n","\n","    def set_offset(self, offset: int):\n","        self.offset = offset\n","\n","    def __data_generation(self, index):\n","        \"\"\"\n","        EEGデータの前処理部分。元コードからの変更多い。\n","        \"\"\"\n","        # バッチサイズのサンプルを含むデータを生成\n","        X = np.zeros(\n","            (CFG.out_samples, CFG.in_channels), dtype=\"float32\"\n","        )  # Size=(10000, 14)\n","\n","        random_divide_signal = False    # ランダムに信号を分割するかのフラグ\n","        row = self.df.iloc[index]  # pandasのデータフレームから指定されたインデックスの行を取得\n","        data = self.eegs[row.eeg_id]  # 脳波データを取得, Size=(10000, 8)\n","\n","        # データの一部を切り出す処理\n","        if CFG.nsamples != CFG.out_samples:\n","            if self.mode == \"train\":\n","                offset = (CFG.sample_delta * random.randint(0, 1000)) // 1000 # ランダムなオフセットを設定し、EEGデータから一部を切り出す\n","            elif not self.offset is None:   # オフセットが指定されている場合\n","                offset = self.offset\n","            else:   # デフォルトのオフセットを使用\n","                offset = CFG.sample_offset\n","\n","            # train で信号をランダムに分割する場合\n","            if self.mode == \"train\" and CFG.random_divide_signal > 0.0 and random.uniform(0.0, 1.0) <= CFG.random_divide_signal:\n","                random_divide_signal = True\n","                multipliers = [(1, 2), (2, 3), (3, 4), (3, 5)] # 信号分割の倍率のリスト\n","                koef_1, koef_2 = multipliers[random.randint(0, 3)] # ランダムに倍率を選択\n","                offset = (koef_1 * offset) // koef_2 # オフセットを調整\n","                data = data[offset:offset+(CFG.out_samples * koef_2) // koef_1,:] # 信号を分割して取得\n","            else:\n","                data = data[offset:offset+CFG.out_samples,:] # 指定された範囲の信号を取得\n","\n","        reverse_signal = False # 信号を反転するかどうかのフラグ\n","        negative_signal = False # 信号を負の値にするかどうかのフラグ\n","        if self.mode == \"train\":\n","            # ランダムに信号を反転する場合\n","            if CFG.random_common_reverse_signal > 0.0 and random.uniform(0.0, 1.0) <= CFG.random_common_reverse_signal:\n","                reverse_signal = True # フラグをTrueに設定\n","            # ランダムに信号を負の値にする場合\n","            if CFG.random_common_negative_signal > 0.0 and random.uniform(0.0, 1.0) <= CFG.random_common_negative_signal:\n","                negative_signal = True # フラグをTrueに設定\n","\n","        # 設定された特徴量ペアに対してループ\n","        for i, (feat_a, feat_b) in enumerate(CFG.map_features):\n","            if self.mode == \"train\" and CFG.random_close_zone > 0.0 and random.uniform(0.0, 1.0) <= CFG.random_close_zone:  # 訓練モードでランダムにゾーンをクローズする場合\n","                continue\n","            \n","            diff_feat = (\n","                data[:, CFG.feature_to_index[feat_a]]\n","                - data[:, CFG.feature_to_index[feat_b]]\n","            ) # 指定された2つの特徴量の差分を計算 Size=(10000,)\n","\n","            if self.mode == \"train\":\n","                if reverse_signal or CFG.random_reverse_signal > 0.0 and random.uniform(0.0, 1.0) <= CFG.random_reverse_signal:\n","                    diff_feat = np.flip(diff_feat) # 信号を反転\n","                if negative_signal or CFG.random_negative_signal > 0.0 and random.uniform(0.0, 1.0) <= CFG.random_negative_signal:\n","                    diff_feat = -diff_feat # 信号を負の値に変換\n","\n","            if not self.bandpass_filter is None: # バンドパスフィルタが設定されている場合\n","                diff_feat = butter_bandpass_filter(\n","                    diff_feat,\n","                    self.bandpass_filter[\"low\"],\n","                    self.bandpass_filter[\"high\"],\n","                    CFG.sampling_rate,\n","                    order=self.bandpass_filter[\"order\"],\n","                ) # バンドパスフィルタを適用\n","            \n","            if random_divide_signal: # 信号が分割されている場合\n","                #diff_feat = cp.asnumpy(cpsig.upfirdn([1.0, 1, 1.0], diff_feat, 2, 3))  # linear interp, rate 2/3\n","                diff_feat = scisig.upfirdn([1.0, 1, 1.0], diff_feat, koef_1, koef_2)  # 線形補間を行いサンプリングレートを変更\n","                diff_feat = diff_feat[0:CFG.out_samples] # 必要な長さに切り詰める\n","\n","            if (\n","                self.mode == \"train\"\n","                and not self.rand_filter is None\n","                and random.uniform(0.0, 1.0) <= self.rand_filter[\"probab\"]\n","            ): # 訓練モードでランダムフィルタが設定されている場合\n","                lowcut = random.randint(\n","                    self.rand_filter[\"low\"], self.rand_filter[\"high\"]\n","                ) # ランダムに低域カットオフ周波数を選択\n","                highcut = lowcut + self.rand_filter[\"band\"] # 高域カットオフ周波数を設定\n","                diff_feat = butter_bandpass_filter(\n","                    diff_feat,\n","                    lowcut,\n","                    highcut,\n","                    CFG.sampling_rate,\n","                    order=self.rand_filter[\"order\"],\n","                ) # ランダムフィルタを適用\n","\n","            X[:, i] = diff_feat # 前処理された特徴量を入力データXに格納\n","\n","        n = CFG.n_map_features # 次の特徴量のインデックス\n","        if len(CFG.freq_channels) > 0: # 周波数領域の特徴量が設定されている場合\n","            for i in range(CFG.n_map_features): # 既存の特徴量に対してループ\n","                diff_feat = X[:, i] # 特徴量を取得\n","                for j, (lowcut, highcut) in enumerate(CFG.freq_channels): # 設定された周波数帯域に対してループ\n","                    band_feat = butter_bandpass_filter(\n","                        diff_feat, lowcut, highcut, CFG.sampling_rate, order=CFG.filter_order,  # 6\n","                    ) # バンドパスフィルタを適用\n","                    X[:, n] = band_feat # フィルタリングされた特徴量を入力データXに格納\n","                    n += 1  # 次の特徴量のインデックスに進む\n","\n","        for spml_feat in CFG.simple_features: # 単純な特徴量が設定されている場合\n","            feat_val = data[:, CFG.feature_to_index[spml_feat]] # 特徴量を取得\n","            \n","            if not self.bandpass_filter is None: # バンドパスフィルタが設定されている場合\n","                feat_val = butter_bandpass_filter(\n","                    feat_val,\n","                    self.bandpass_filter[\"low\"],\n","                    self.bandpass_filter[\"high\"],\n","                    CFG.sampling_rate,\n","                    order=self.bandpass_filter[\"order\"],\n","                ) # バンドパスフィルタを適用\n","\n","            if (\n","                self.mode == \"train\"\n","                and not self.rand_filter is None\n","                and random.uniform(0.0, 1.0) <= self.rand_filter[\"probab\"]\n","            ): # 訓練モードでランダムフィルタが設定されている場合\n","                lowcut = random.randint(\n","                    self.rand_filter[\"low\"], self.rand_filter[\"high\"]\n","                ) # ランダムに低域カットオフ周波数を選択\n","                highcut = lowcut + self.rand_filter[\"band\"]\n","                feat_val = butter_bandpass_filter(\n","                    feat_val,\n","                    lowcut,\n","                    highcut,\n","                    CFG.sampling_rate,\n","                    order=self.rand_filter[\"order\"],\n","                ) # ランダムフィルタを適用\n","\n","            X[:, n] = feat_val # 前処理された特徴量を入力データXに格納\n","            n += 1 # 次の特徴量のインデックスに進む\n","            \n","        # [-1024, 1024] を超えるエッジをトリム(切り詰め)\n","        X = np.clip(X, -1024, 1024)\n","\n","        # NaN をゼロに置き換え、すべてを 32 で割ります\n","        X = np.nan_to_num(X, nan=0) / 32.0\n","\n","        # バンドパスフィルターで20Hzの上限をカットします。\n","        X = butter_lowpass_filter(X, order=CFG.filter_order)  # 4\n","\n","        y_prob = np.zeros(CFG.target_size, dtype=\"float32\")  # ターゲット変数y_probを初期化 (Size=(6,))\n","        if self.mode != \"test\":  # テストモードでない場合\n","            y_prob = row[CFG.target_cols].values.astype(np.float32)  # データフレームからターゲット変数の値を取得\n","\n","        return X, y_prob # 前処理された入力データXとターゲット変数y_probを返す"]},{"cell_type":"markdown","metadata":{},"source":["# Helper functions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class KLDivLossWithLogits(nn.KLDivLoss):\n","    def __init__(self):\n","        super().__init__(reduction=\"batchmean\")\n","\n","    def forward(self, y, t):\n","        y = nn.functional.log_softmax(y, dim=1)\n","        loss = super().forward(y, t)\n","        return loss\n","\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def seed_torch(seed):\n","    random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    # torch.backends.cudnn.benchmark = True  # このオプションには大量の GPU メモリが必要です\n","    # pl.seed_everything(seed)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.031018,"end_time":"2024-02-20T13:42:28.75746","exception":false,"start_time":"2024-02-20T13:42:28.726442","status":"completed"},"tags":[]},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T13:42:28.820219Z","iopub.status.busy":"2024-02-20T13:42:28.819862Z","iopub.status.idle":"2024-02-20T13:42:28.842869Z","shell.execute_reply":"2024-02-20T13:42:28.842124Z"},"papermill":{"duration":0.05674,"end_time":"2024-02-20T13:42:28.844768","exception":false,"start_time":"2024-02-20T13:42:28.788028","status":"completed"},"tags":[]},"outputs":[],"source":["class ResNet_1D_Block(nn.Module):\n","    def __init__(\n","        self,\n","        in_channels,\n","        out_channels,\n","        kernel_size,\n","        stride,\n","        padding,\n","        downsampling,\n","        dilation=1,\n","        groups=1,\n","        dropout=0.0,\n","    ):\n","        super(ResNet_1D_Block, self).__init__()\n","\n","        self.bn1 = nn.BatchNorm1d(num_features=in_channels) # バッチ正規化\n","        # self.relu = nn.ReLU(inplace=False)                # ReLU2層\n","        # self.relu_1 = nn.PReLU()\n","        # self.relu_2 = nn.PReLU()\n","        self.relu_1 = nn.Hardswish()\n","        self.relu_2 = nn.Hardswish()\n","\n","        self.dropout = nn.Dropout(p=dropout, inplace=False) # ドロップアウト\n","        self.conv1 = nn.Conv1d(                             # 畳み込み層\n","            in_channels=in_channels,\n","            out_channels=out_channels,\n","            kernel_size=kernel_size,\n","            stride=stride,\n","            padding=padding,\n","            dilation=dilation,\n","            groups=groups,\n","            bias=False,\n","        )\n","\n","        self.bn2 = nn.BatchNorm1d(num_features=out_channels) # バッチ正規化\n","        self.conv2 = nn.Conv1d(                              # 畳み込み層\n","            in_channels=out_channels,\n","            out_channels=out_channels,\n","            kernel_size=kernel_size,\n","            stride=stride,\n","            padding=padding,\n","            dilation=dilation,\n","            groups=groups,\n","            bias=False,\n","        )\n","\n","        self.maxpool = nn.MaxPool1d(                        # MaxPooling\n","            kernel_size=2,\n","            stride=2,\n","            padding=0,\n","            dilation=dilation,\n","        )\n","        self.downsampling = downsampling                    # ダウンサンプリング\n","\n","    def forward(self, x):                                   # 順伝搬\n","        identity = x\n","\n","        out = self.bn1(x)\n","        out = self.relu_1(out)\n","        out = self.dropout(out)\n","        out = self.conv1(out)\n","        out = self.bn2(out)\n","        out = self.relu_2(out)\n","        out = self.dropout(out)\n","        out = self.conv2(out)\n","\n","        out = self.maxpool(out)\n","        identity = self.downsampling(x)\n","\n","        out += identity\n","        return out\n","\n","\n","class EEGNet(nn.Module):\n","    def __init__(\n","        self,\n","        kernels,\n","        in_channels,\n","        fixed_kernel_size,\n","        num_classes,\n","        linear_layer_features,\n","        dilation=1,\n","        groups=1,\n","    ):\n","        super(EEGNet, self).__init__()\n","        self.kernels = kernels\n","        self.planes = 24\n","        self.parallel_conv = nn.ModuleList()\n","        self.in_channels = in_channels\n","\n","        for i, kernel_size in enumerate(list(self.kernels)):\n","            sep_conv = nn.Conv1d(\n","                in_channels=in_channels,\n","                out_channels=self.planes,\n","                kernel_size=(kernel_size),\n","                stride=1,\n","                padding=0,\n","                dilation=dilation,\n","                groups=groups,\n","                bias=False,\n","            )\n","            self.parallel_conv.append(sep_conv)\n","\n","        self.bn1 = nn.BatchNorm1d(num_features=self.planes)\n","        # self.relu = nn.ReLU(inplace=False)\n","        # self.relu_1 = nn.ReLU()\n","        # self.relu_2 = nn.ReLU()\n","        self.relu_1 = nn.SiLU()\n","        self.relu_2 = nn.SiLU()\n","\n","        self.conv1 = nn.Conv1d(\n","            in_channels=self.planes,\n","            out_channels=self.planes,\n","            kernel_size=fixed_kernel_size,\n","            stride=2,\n","            padding=2,\n","            dilation=dilation,\n","            groups=groups,\n","            bias=False,\n","        )\n","\n","        self.block = self._make_resnet_layer(\n","            kernel_size=fixed_kernel_size,\n","            stride=1,\n","            dilation=dilation,\n","            groups=groups,\n","            padding=fixed_kernel_size // 2,\n","        )\n","        self.bn2 = nn.BatchNorm1d(num_features=self.planes)\n","        self.avgpool = nn.AvgPool1d(kernel_size=6, stride=6, padding=2)\n","\n","        self.rnn = nn.GRU(\n","            input_size=self.in_channels,\n","            hidden_size=128,\n","            num_layers=1,\n","            bidirectional=True,\n","            # dropout=0.2,\n","        )\n","\n","        self.fc = nn.Linear(in_features=linear_layer_features, out_features=num_classes)\n","\n","    def _make_resnet_layer(\n","        self,\n","        kernel_size,\n","        stride,\n","        dilation=1,\n","        groups=1,\n","        blocks=9,\n","        padding=0,\n","        dropout=0.0,\n","    ):\n","        layers = []\n","        downsample = None\n","        base_width = self.planes\n","\n","        for i in range(blocks):\n","            downsampling = nn.Sequential(\n","                nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n","            )\n","            layers.append(\n","                ResNet_1D_Block(\n","                    in_channels=self.planes,\n","                    out_channels=self.planes,\n","                    kernel_size=kernel_size,\n","                    stride=stride,\n","                    padding=padding,\n","                    downsampling=downsampling,\n","                    dilation=dilation,\n","                    groups=groups,\n","                    dropout=dropout,\n","                )\n","            )\n","        return nn.Sequential(*layers)\n","\n","    def extract_features(self, x):\n","        x = x.permute(0, 2, 1)\n","\n","        out_sep = []\n","        for i in range(len(self.kernels)):\n","            sep = self.parallel_conv[i](x)\n","            out_sep.append(sep)\n","\n","        out = torch.cat(out_sep, dim=2)\n","        out = self.bn1(out)\n","        out = self.relu_1(out)\n","        out = self.conv1(out)\n","\n","        out = self.block(out)\n","        out = self.bn2(out)\n","        out = self.relu_2(out)\n","        out = self.avgpool(out)\n","\n","        out = out.reshape(out.shape[0], -1)\n","        rnn_out, _ = self.rnn(x.permute(0, 2, 1))\n","        new_rnn_h = rnn_out[:, -1, :]\n","\n","        new_out = torch.cat([out, new_rnn_h], dim=1)\n","        return new_out\n","\n","    def forward(self, x):\n","        new_out = self.extract_features(x)\n","        result = self.fc(new_out)\n","        return result"]},{"cell_type":"markdown","metadata":{},"source":["# Adan Optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T13:42:29.576789Z","iopub.status.busy":"2024-02-20T13:42:29.576341Z","iopub.status.idle":"2024-02-20T13:42:29.600941Z","shell.execute_reply":"2024-02-20T13:42:29.600218Z"},"papermill":{"duration":0.058157,"end_time":"2024-02-20T13:42:29.60282","exception":false,"start_time":"2024-02-20T13:42:29.544663","status":"completed"},"tags":[]},"outputs":[],"source":["class Adan(Optimizer):\n","    \"\"\"\n","    Implements a pytorch variant of Adan\n","    Adan was proposed in\n","    Adan: Adaptive Nesterov Momentum Algorithm for Faster Optimizing Deep Models[J]. arXiv preprint arXiv:2208.06677, 2022.\n","    https://arxiv.org/abs/2208.06677\n","    Arguments:\n","        params (iterable): iterable of parameters to optimize or dicts defining parameter groups.\n","        lr (float, optional): learning rate. (default: 1e-3)\n","        betas (Tuple[float, float, flot], optional): coefficients used for computing\n","            running averages of gradient and its norm. (default: (0.98, 0.92, 0.99))\n","        eps (float, optional): term added to the denominator to improve\n","            numerical stability. (default: 1e-8)\n","        weight_decay (float, optional): decoupled weight decay (L2 penalty) (default: 0)\n","        max_grad_norm (float, optional): value used to clip\n","            global grad norm (default: 0.0 no clip)\n","        no_prox (bool): how to perform the decoupled weight decay (default: False)\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        params,\n","        lr=1e-3,\n","        betas=(0.98, 0.92, 0.99),\n","        eps=1e-8,\n","        weight_decay=0.2,\n","        max_grad_norm=0.0,\n","        no_prox=False,\n","    ):\n","        if not 0.0 <= max_grad_norm:\n","            raise ValueError(\"Invalid Max grad norm: {}\".format(max_grad_norm))\n","        if not 0.0 <= lr:\n","            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n","        if not 0.0 <= eps:\n","            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n","        if not 0.0 <= betas[0] < 1.0:\n","            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n","        if not 0.0 <= betas[1] < 1.0:\n","            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n","        if not 0.0 <= betas[2] < 1.0:\n","            raise ValueError(\"Invalid beta parameter at index 2: {}\".format(betas[2]))\n","        defaults = dict(\n","            lr=lr,\n","            betas=betas,\n","            eps=eps,\n","            weight_decay=weight_decay,\n","            max_grad_norm=max_grad_norm,\n","            no_prox=no_prox,\n","        )\n","        super(Adan, self).__init__(params, defaults)\n","\n","    def __setstate__(self, state):\n","        super(Adan, self).__setstate__(state)\n","        for group in self.param_groups:\n","            group.setdefault(\"no_prox\", False)\n","\n","    @torch.no_grad()\n","    def restart_opt(self):\n","        for group in self.param_groups:\n","            group[\"step\"] = 0\n","            for p in group[\"params\"]:\n","                if p.requires_grad:\n","                    state = self.state[p]\n","                    # State initialization\n","\n","                    # Exponential moving average of gradient values\n","                    state[\"exp_avg\"] = torch.zeros_like(p)\n","                    # Exponential moving average of squared gradient values\n","                    state[\"exp_avg_sq\"] = torch.zeros_like(p)\n","                    # Exponential moving average of gradient difference\n","                    state[\"exp_avg_diff\"] = torch.zeros_like(p)\n","\n","    @torch.no_grad()\n","    def step(self):\n","        \"\"\"\n","        Performs a single optimization step.\n","        \"\"\"\n","        if self.defaults[\"max_grad_norm\"] > 0:\n","            device = self.param_groups[0][\"params\"][0].device\n","            global_grad_norm = torch.zeros(1, device=device)\n","\n","            max_grad_norm = torch.tensor(self.defaults[\"max_grad_norm\"], device=device)\n","            for group in self.param_groups:\n","\n","                for p in group[\"params\"]:\n","                    if p.grad is not None:\n","                        grad = p.grad\n","                        global_grad_norm.add_(grad.pow(2).sum())\n","\n","            global_grad_norm = torch.sqrt(global_grad_norm)\n","\n","            clip_global_grad_norm = torch.clamp(\n","                max_grad_norm / (global_grad_norm + group[\"eps\"]), max=1.0\n","            )\n","        else:\n","            clip_global_grad_norm = 1.0\n","\n","        for group in self.param_groups:\n","            beta1, beta2, beta3 = group[\"betas\"]\n","            # assume same step across group now to simplify things\n","            # per parameter step can be easily support by making it tensor, or pass list into kernel\n","            if \"step\" in group:\n","                group[\"step\"] += 1\n","            else:\n","                group[\"step\"] = 1\n","\n","            bias_correction1 = 1.0 - beta1 ** group[\"step\"]\n","            bias_correction2 = 1.0 - beta2 ** group[\"step\"]\n","            bias_correction3 = 1.0 - beta3 ** group[\"step\"]\n","\n","            for p in group[\"params\"]:\n","                if p.grad is None:\n","                    continue\n","\n","                state = self.state[p]\n","                if len(state) == 0:\n","                    state[\"exp_avg\"] = torch.zeros_like(p)\n","                    state[\"exp_avg_sq\"] = torch.zeros_like(p)\n","                    state[\"exp_avg_diff\"] = torch.zeros_like(p)\n","\n","                grad = p.grad.mul_(clip_global_grad_norm)\n","                if \"pre_grad\" not in state or group[\"step\"] == 1:\n","                    state[\"pre_grad\"] = grad\n","\n","                copy_grad = grad.clone()\n","\n","                exp_avg, exp_avg_sq, exp_avg_diff = (\n","                    state[\"exp_avg\"],\n","                    state[\"exp_avg_sq\"],\n","                    state[\"exp_avg_diff\"],\n","                )\n","                diff = grad - state[\"pre_grad\"]\n","\n","                update = grad + beta2 * diff\n","                exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)  # m_t\n","                exp_avg_diff.mul_(beta2).add_(diff, alpha=1 - beta2)  # diff_t\n","                exp_avg_sq.mul_(beta3).addcmul_(update, update, value=1 - beta3)  # n_t\n","\n","                denom = ((exp_avg_sq).sqrt() / math.sqrt(bias_correction3)).add_(\n","                    group[\"eps\"]\n","                )\n","                update = (\n","                    (\n","                        exp_avg / bias_correction1\n","                        + beta2 * exp_avg_diff / bias_correction2\n","                    )\n","                ).div_(denom)\n","\n","                if group[\"no_prox\"]:\n","                    p.data.mul_(1 - group[\"lr\"] * group[\"weight_decay\"])\n","                    p.add_(update, alpha=-group[\"lr\"])\n","                else:\n","                    p.add_(update, alpha=-group[\"lr\"])\n","                    p.data.div_(1 + group[\"lr\"] * group[\"weight_decay\"])\n","\n","                state[\"pre_grad\"] = copy_grad"]},{"cell_type":"markdown","metadata":{},"source":["# Train func"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_fn(\n","    stage, fold, train_loader, model, criterion, optimizer, epoch, scheduler, device\n","):\n","    model.train()\n","\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","\n","    for step, batch in enumerate(train_loader):\n","        eegs = batch[\"eeg\"].to(device)\n","        labels = batch[\"labels\"].to(device)\n","        batch_size = labels.size(0)\n","\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            y_preds = model(eegs)\n","            loss = criterion(F.log_softmax(y_preds, dim=1), labels)\n","\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","\n","        losses.update(loss.item(), batch_size)\n","\n","        scaler.scale(loss).backward()\n","\n","        grad_norm = torch.nn.utils.clip_grad_norm_(\n","            model.parameters(), CFG.max_grad_norm\n","        )\n","\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            global_step += 1\n","            # モデル内のパラメータの勾配を初期化なし\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","\n","        if CFG.log_show and (\n","            step % CFG.log_step == 0 or step == (len(train_loader) - 1)\n","        ):\n","            # remain=timeSince(start, float(step + 1) / len(train_loader))\n","            LOGGER.info(\n","                f\"Epoch {epoch+1} [{step}/{len(train_loader)}] Loss: {losses.val:.4f} Loss Avg:{losses.avg:.4f}\"\n","            )\n","            # \"Elapsed {remain:s} Grad: {grad_norm:.4f}  LR: {cheduler.get_lr()[0]:.8f}\"\n","\n","        if CFG.wandb:\n","            wandb.log(\n","                {\n","                    f\"[fold{fold}] loss\": losses.val,\n","                    f\"[fold{fold}] lr\": scheduler.get_lr()[0],\n","                }\n","            )\n","    return losses.avg"]},{"cell_type":"markdown","metadata":{},"source":["# Valid Func"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def valid_fn(stage, epoch, valid_loader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    targets = []\n","    start = end = time.time()\n","\n","    for step, batch in enumerate(valid_loader):\n","        eegs = batch[\"eeg\"].to(device)\n","        labels = batch[\"labels\"].to(device)\n","        batch_size = labels.size(0)\n","\n","        with torch.no_grad():\n","            y_preds = model(eegs)\n","            loss = criterion(F.log_softmax(y_preds, dim=1), labels)\n","\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","\n","        losses.update(loss.item(), batch_size)\n","        preds.append(nn.Softmax(dim=1)(y_preds).to(\"cpu\").numpy())\n","        targets.append(labels.to(\"cpu\").numpy())\n","        end = time.time()\n","\n","        if CFG.log_show and (\n","            step % CFG.log_step == 0 or step == (len(valid_loader) - 1)\n","        ):\n","            # remain=timeSince(start, float(step + 1) / len(valid_loader))\n","            LOGGER.info(\n","                f\"Epoch {epoch+1} VALIDATION: [{step}/{len(valid_loader)}] Val Loss: {losses.val:.4f} Val Loss Avg: {losses.avg:.4f}\"\n","            )\n","            # Elapsed {remain:s}\n","\n","    predictions = np.concatenate(preds)\n","    targets = np.concatenate(targets)\n","\n","    return losses.avg, predictions"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.031254,"end_time":"2024-02-20T13:42:29.808216","exception":false,"start_time":"2024-02-20T13:42:29.776962","status":"completed"},"tags":[]},"source":["# Build Optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def build_optimizer(cfg, model, device, epochs, num_batches_per_epoch):\n","    lr = cfg.lr\n","    # lr = default_configs[\"lr\"]\n","    if cfg.optimizer == \"SAM\":\n","        base_optimizer = (\n","            torch.optim.SGD\n","        )  # define an optimizer for the \"sharpness-aware\" update\n","        optimizer_model = SAM(\n","            model.parameters(),\n","            base_optimizer,\n","            lr=lr,\n","            momentum=0.9,\n","            weight_decay=cfg.weight_decay,\n","            adaptive=True,\n","        )\n","    elif cfg.optimizer == \"Ranger21\":\n","        optimizer_model = Ranger21(\n","            model.parameters(),\n","            lr=lr,\n","            weight_decay=cfg.weight_decay,\n","            num_epochs=epochs,\n","            num_batches_per_epoch=num_batches_per_epoch,\n","        )\n","    elif cfg.optimizer == \"SGD\":\n","        optimizer_model = torch.optim.SGD(\n","            model.parameters(), lr=lr, weight_decay=cfg.weight_decay, momentum=0.9\n","        )\n","    elif cfg.optimizer == \"Adam\":\n","        optimizer_model = Adam(model.parameters(), lr=lr, weight_decay=CFG.weight_decay)\n","    elif cfg.optimizer == \"AdamW\":\n","        optimizer_model = AdamW(\n","            model.parameters(), lr=lr, weight_decay=CFG.weight_decay\n","        )\n","    elif cfg.optimizer == \"Lion\":\n","        optimizer_model = Lion(model.parameters(), lr=lr, weight_decay=cfg.weight_decay)\n","    elif cfg.optimizer == \"Adan\":\n","        optimizer_model = Adan(model.parameters(), lr=lr, weight_decay=cfg.weight_decay)\n","\n","    return optimizer_model"]},{"cell_type":"markdown","metadata":{},"source":["# Scheduler"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_scheduler(optimizer, epochs, steps_per_epoch):\n","    if CFG.scheduler == \"ReduceLROnPlateau\":\n","        scheduler = ReduceLROnPlateau(optimizer, **CFG.reduce_params)\n","    elif CFG.scheduler == \"CosineAnnealingLR\":\n","        scheduler = CosineAnnealingLR(optimizer, **CFG.cosanneal_params)\n","    elif CFG.scheduler == \"CosineAnnealingWarmRestarts\":\n","        scheduler = CosineAnnealingWarmRestarts(optimizer, **CFG.cosanneal_res_params)\n","    elif CFG.scheduler == \"OneCycleLR\":\n","        scheduler = OneCycleLR(\n","            optimizer=optimizer,\n","            epochs=epochs,\n","            pct_start=0.0,\n","            steps_per_epoch=steps_per_epoch,\n","            max_lr=CFG.lr,\n","            div_factor=25,\n","            final_div_factor=4.0e-01,\n","        )\n","    return scheduler"]},{"cell_type":"markdown","metadata":{},"source":["# Train Loop"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T13:42:29.872367Z","iopub.status.busy":"2024-02-20T13:42:29.872072Z","iopub.status.idle":"2024-02-20T13:42:29.895963Z","shell.execute_reply":"2024-02-20T13:42:29.895215Z"},"papermill":{"duration":0.05868,"end_time":"2024-02-20T13:42:29.897814","exception":false,"start_time":"2024-02-20T13:42:29.839134","status":"completed"},"tags":[]},"outputs":[],"source":["def train_loop(stage, epochs, folds, fold, directory, prev_dir, eggs):\n","    train_folds = folds[folds[\"fold\"] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds[\"fold\"] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds[CFG.target_cols].values\n","\n","    train_dataset = EEGDataset(\n","        train_folds,\n","        batch_size=CFG.batch_size,\n","        mode=\"train\",\n","        eegs=eggs,\n","        bandpass_filter=CFG.bandpass_filter,\n","        rand_filter=CFG.rand_filter,\n","    )\n","        \n","    valid_dataset = EEGDataset(\n","        valid_folds,\n","        batch_size=CFG.batch_size,\n","        mode=\"valid\",\n","        eegs=eggs,\n","        bandpass_filter=CFG.bandpass_filter,\n","        #rand_filter=CFG.rand_filter,\n","    )\n","\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=True,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=True,\n","    )\n","\n","    valid_loader = DataLoader(\n","        valid_dataset,\n","        batch_size=CFG.batch_size * CFG.batch_koef_valid,\n","        shuffle=False,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=False,\n","    )\n","\n","    LOGGER.info(\n","        f\"========== stage: {stage} fold: {fold} training {len(train_loader)} / {len(valid_loader)} ==========\"\n","    )\n","\n","    model = EEGNet(\n","        kernels=CFG.kernels,\n","        in_channels=CFG.in_channels,\n","        fixed_kernel_size=CFG.fixed_kernel_size,\n","        num_classes=CFG.target_size,\n","        linear_layer_features=CFG.linear_layer_features,\n","    )\n","\n","    # 2stage学習\n","    if stage > 1:\n","        model_weight = f\"{prev_dir}{CFG.model_name}_ver-{CFG.VERSION}_stage-{stage-1}_fold-{fold}_best.pth\"\n","        checkpoint = torch.load(model_weight, map_location=device)\n","        model.load_state_dict(checkpoint[\"model\"])\n","\n","    model.to(device)\n","\n","    # CPMP: wrap the model to use all GPUs\n","    if CFG.parallel:\n","        model = nn.DataParallel(model)\n","\n","    optimizer = build_optimizer(\n","        CFG, model, device, epochs=epochs, num_batches_per_epoch=len(train_loader)\n","    )\n","    scheduler = get_scheduler(\n","        optimizer, epochs=epochs, steps_per_epoch=len(train_loader)\n","    )\n","    criterion = nn.KLDivLoss(reduction=\"batchmean\")\n","\n","    best_score = np.inf\n","    for epoch in range(epochs):\n","        start_time = time.time()\n","\n","        # train\n","        avg_loss = train_fn(\n","            stage,\n","            fold,\n","            train_loader,\n","            model,\n","            criterion,\n","            optimizer,\n","            epoch,\n","            scheduler,\n","            device,\n","        )\n","\n","        # eval\n","        valid_dataset.set_offset(CFG.sample_offset)\n","        avg_val_loss, predictions = valid_fn(\n","            stage,\n","            epoch,\n","            valid_loader,\n","            model,\n","            criterion,\n","            device,\n","        )\n","        \n","        avg_loss_line = ''\n","        if CFG.multi_validation:\n","            multi_avg_val_loss = np.zeros(CFG.n_split_samples)\n","            start = (2 * CFG.sample_delta) // CFG.n_split_samples\n","            finish = (3 * CFG.sample_delta) // CFG.n_split_samples\n","            delta = (finish - start) // 5\n","            for i in range(CFG.n_split_samples):\n","                valid_dataset.set_offset(start)\n","                multi_avg_val_loss[i], _ = valid_fn(\n","                    stage,\n","                    epoch,\n","                    valid_loader,\n","                    model,\n","                    criterion,\n","                    device,\n","                )\n","                avg_loss_line += f\" {multi_avg_val_loss[i]:.4f}\"\n","                start += delta\n","            avg_loss_line += f\" mean={np.mean(multi_avg_val_loss):.4f}\"\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(\n","            f\"Epoch {epoch+1} Avg Train Loss: {avg_loss:.4f} Avg Valid Loss: {avg_val_loss:.4f} / {avg_loss_line}\"\n","        )\n","        #   time: {elapsed:.0f}s\n","        if CFG.wandb:\n","            wandb.log(\n","                {\n","                    f\"[fold{fold}] stage\": stage,\n","                    f\"[fold{fold}] epoch\": epoch + 1,\n","                    f\"[fold{fold}] avg_train_loss\": avg_loss,\n","                    f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n","                    #f\"[fold{fold}] score\": score,\n","                }\n","            )\n","\n","        if CFG.save_all_models:\n","            torch.save(\n","                {\"model\": model.module.state_dict(), \"predictions\": predictions},\n","                f\"{directory}{CFG.model_name}_ver-{CFG.VERSION}_stage-{stage}_fold-{fold}_epoch-{epoch}_val-{avg_val_loss:.4f}_train-{avg_loss:.4f}.pth\",\n","            )\n","\n","        if best_score > avg_val_loss:\n","            best_score = avg_val_loss\n","            LOGGER.info(f\"Epoch {epoch+1} Save Best Valid Loss: {avg_val_loss:.4f}\")\n","            # CPMP: save the original model. It is stored as the module attribute of the DP model.\n","            torch.save(\n","                {\"model\": model.module.state_dict(), \"predictions\": predictions},\n","                f\"{directory}{CFG.model_name}_ver-{CFG.VERSION}_stage-{stage}_fold-{fold}_best.pth\",\n","            )\n","\n","    predictions = torch.load(\n","        f\"{directory}{CFG.model_name}_ver-{CFG.VERSION}_stage-{stage}_fold-{fold}_best.pth\",\n","        map_location=torch.device(\"cpu\"),\n","    )[\"predictions\"]\n","\n","    # valid_folds[[f\"pred_{c}\" for c in CFG.target_cols]] = predictions\n","    valid_folds[CFG.pred_cols] = predictions\n","    valid_folds[CFG.target_cols] = valid_labels\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return valid_folds, best_score"]},{"cell_type":"markdown","metadata":{},"source":["# Load train data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train = pd.read_csv(CFG.file_train)\n","TARGETS = train.columns[-6:]\n","print(\"Train shape:\", train.shape)\n","print(\"Targets\", list(TARGETS))\n","\n","train[\"total_evaluators\"] = train[CFG.target_cols].sum(axis=1)\n","\n","train_uniq = train.drop_duplicates(subset=[\"eeg_id\"] + list(TARGETS))\n","\n","print(f\"There are {train.patient_id.nunique()} patients in the training data.\")\n","print(f\"There are {train.eeg_id.nunique()} EEG IDs in the training data.\")\n","print(f\"There are {train_uniq.shape[0]} unique eeg_id + votes in the training data.\")\n","\n","if CFG.visualize:\n","    train_uniq.eeg_id.value_counts().value_counts().plot(\n","        kind=\"bar\",\n","        title=f\"Distribution of Count of EEG w Unique Vote: \"\n","        f\"{train_uniq.shape[0]} examples\",\n","    )\n","\n","del train_uniq\n","_ = gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if CFG.visualize:\n","    plt.figure(figsize=(10, 6))\n","    plt.hist(train[\"total_evaluators\"], bins=10, color=\"blue\", edgecolor=\"black\")\n","    plt.title(\"Histogram of Total Evaluators\")\n","    plt.xlabel(\"Total Evaluators\")\n","    plt.ylabel(\"Frequency\")\n","    plt.grid(True)\n","    plt.show()\n","\n","tst_eeg_df = pd.read_parquet(CFG.file_features_test)\n","tst_eeg_features = tst_eeg_df.columns\n","print(f\"There are {len(tst_eeg_features)} raw eeg features\")\n","print(list(tst_eeg_features))\n","del tst_eeg_df\n","_ = gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["# Split Data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# %%time\n","all_eeg_specs = np.load(CFG.file_eeg_specs, allow_pickle=True).item()\n","\n","train = train[train[\"label_id\"].isin(all_eeg_specs.keys())].copy()\n","print(train.shape[0])\n","\n","# y_data = train[TARGETS].values + 0.166666667  # Regularization value\n","y_data = train[TARGETS].values\n","y_data = y_data / y_data.sum(axis=1, keepdims=True)\n","train[TARGETS] = y_data\n","\n","train[\"target\"] = train[\"expert_consensus\"]\n","\n","train[train['total_evaluators'] == CFG.test_total_eval].groupby(['expert_consensus','total_evaluators']).count()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if CFG.test_total_eval > 0:\n","    train['key_id'] = range(train.shape[0])\n","\n","    train_pop_olds = []\n","    for total_eval in CFG.total_evals_old:\n","        if type(total_eval) is list:\n","            pop_idx = (train[\"total_evaluators\"] >= total_eval[0][0]) & (\n","                train[\"total_evaluators\"] < total_eval[0][1]\n","            ) | (train[\"total_evaluators\"] >= total_eval[1][0]) & (\n","                train[\"total_evaluators\"] < total_eval[1][1]\n","            )\n","        else:\n","            pop_idx = (train[\"total_evaluators\"] >= total_eval[0]) & (\n","                train[\"total_evaluators\"] < total_eval[1]\n","            )\n","\n","        train_pop = train[pop_idx].copy().reset_index()\n","\n","        sgkf = GroupKFold(n_splits=CFG.n_fold)\n","        train_pop[\"fold\"] = -1\n","        for fold_id, (_, val_idx) in enumerate(\n","            sgkf.split(train_pop, y=train_pop[\"target\"], groups=train_pop[\"patient_id\"])\n","        ):\n","            train_pop.loc[val_idx, \"fold\"] = fold_id\n","\n","        train_pop_olds.append(train_pop)\n","        print(train_pop.shape[0])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_pops = [] # 各stageのtrain用データフレームをリストで持つ。[stage1用df, stage2用df, ...]\n","for eval_list in CFG.total_evaluators:\n","    result=[]\n","    train_pop = train  \n","    for eval_dict in eval_list:\n","        band = eval_dict['band'] # 投票数の範囲(min, max)を取得\n","        pop_idx = (train_pop[\"total_evaluators\"] >= band[0]) # band[0] = min\n","        pop_idx &= (train_pop[\"total_evaluators\"] <= band[1]) # band[1] = max\n","        for exclude in eval_dict['excl_evals']:\n","            pop_idx &= ~(train_pop['expert_consensus'] == exclude)\n","            pass\n","        result.append(train_pop[pop_idx])\n","    train_pop = pd.concat(result).copy().reset_index()\n","\n","    sgkf = GroupKFold(n_splits=CFG.n_fold)\n","    train_pop[\"fold\"] = -1\n","    for fold_id, (_, val_idx) in enumerate(\n","        sgkf.split(train_pop, y=train_pop[\"target\"], groups=train_pop[\"patient_id\"])\n","    ):\n","        train_pop.loc[val_idx, \"fold\"] = fold_id\n","\n","    train_pops.append(train_pop) # 各stage用のdfをリストに入れる\n","    print(train_pop.shape[0])\n","\n","train_0 = train_pops[0]\n","train_0[train_0['total_evaluators'] == CFG.test_total_eval].groupby(['expert_consensus','total_evaluators']).count()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# if CFG.test_total_eval > 0:\n","#     df_old = train_pop_olds[0].copy(deep=True).set_index(['key_id'], drop=True).drop(columns=['fold'])\n","#     df_new = train_pops[0].copy(deep=True).set_index(['key_id'], drop=True).drop(columns=['fold'])\n","\n","#     #outer merge the two DataFrames, adding an indicator column called 'Exist'\n","#     diff_df = pd.merge(df_old, df_new, how='outer', indicator='Exist')\n","\n","#     #find which rows don't exist in both DataFrames\n","#     diff_df = diff_df.loc[diff_df['Exist'] != 'both']\n","#     display(diff_df)\n","\n","#     del df_old, df_new, diff_df, train_pop_olds\n","#     _ = gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if CFG.visualize:\n","    print(\"Pop 1: train unique eeg_id + votes shape:\", train_pops[0].shape)\n","    plt.figure(figsize=(10, 6))\n","    plt.hist(train[\"total_evaluators\"], bins=10, color=\"blue\", edgecolor=\"black\")\n","    plt.title(\"Histogram of Total Evaluators\")\n","    plt.xlabel(\"Total Evaluators\")\n","    plt.ylabel(\"Frequency\")\n","    plt.grid(True)\n","    plt.show()\n","\n","del all_eeg_specs\n","_ = gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["# Deduplicate Train EEG Id"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","# Chrisのコード\n","# EEGデータのParquetファイルをNumpy辞書に変換\n","# eeg_from_parquet関数で、生のEEGデータに対して前処理をおこなう\n","\n","if CFG.create_eegs:\n","    all_eegs = {}\n","    visualize = 1 if CFG.visualize else 0\n","    eeg_ids = train.eeg_id.unique()\n","\n","    for i, eeg_id in tqdm(enumerate(eeg_ids)):\n","\n","        # numpy 配列の Python 辞書に EEG を保存\n","        eeg_path = CFG.path_train / f\"{eeg_id}.parquet\"\n","\n","        # 真ん中の50秒部分を切り取って真ん中のNaNを詰める\n","        data = eeg_from_parquet(eeg_path, display=i < visualize)\n","        all_eegs[eeg_id] = data\n","\n","        if i == visualize:\n","            if CFG.create_eegs:\n","                print(\n","                    f\"Processing {train['eeg_id'].nunique()} eeg parquets... \", end=\"\"\n","                )\n","            else:\n","                print(f\"Reading {len(eeg_ids)} eeg NumPys from disk.\")\n","                break\n","    np.save(\"./eegs\", all_eegs)\n","\n","else:\n","    all_eegs = np.load(CFG.file_raw_eeg, allow_pickle=True).item()\n","\n","if CFG.visualize:\n","    frequencies = [1, 2, 4, 8, 16][::-1]  # frequencies in Hz\n","    x = [all_eegs[eeg_ids[0]][:, 0]]  # select one EEG feature\n","\n","    for frequency in frequencies:\n","        x.append(butter_lowpass_filter(x[0], cutoff_freq=frequency))\n","\n","    plt.figure(figsize=(12, 8))\n","    plt.plot(range(CFG.nsamples), x[0], label=\"without filter\")\n","    for k in range(1, len(x)):\n","        plt.plot(\n","            range(CFG.nsamples),\n","            x[k] - k * (x[0].max() - x[0].min()),\n","            label=f\"with filter {frequencies[k-1]}Hz\",\n","        )\n","\n","    plt.legend()\n","    plt.yticks([])\n","    plt.title(\"Butter Low-Pass Filter Examples\", size=18)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if CFG.visualize:\n","    train_dataset = EEGDataset(\n","        train_pops[0], batch_size=CFG.batch_size, eegs=all_eegs, mode=\"train\"\n","    )\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=False,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=True,\n","    )\n","    output = train_dataset[0]\n","    X, y = output[\"eeg\"], output[\"labels\"]\n","    print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n","\n","    iot = torch.randn(2, CFG.nsamples, CFG.in_channels)  # .cuda()\n","    model = EEGNet(\n","        kernels=CFG.kernels,\n","        in_channels=CFG.in_channels,\n","        fixed_kernel_size=CFG.fixed_kernel_size,\n","        num_classes=CFG.target_size,\n","        linear_layer_features=CFG.linear_layer_features,\n","    )\n","    output = model(iot)\n","    print(output.shape)\n","\n","    for batch in train_loader:\n","        X = batch.pop(\"eeg\")\n","        y = batch.pop(\"labels\")\n","        for item in range(4):\n","            plt.figure(figsize=(20, 4))\n","            offset = 0\n","            for col in range(X.shape[-1]):\n","                if col != 0:\n","                    offset -= X[item, :, col].min()\n","                plt.plot(\n","                    range(CFG.nsamples),\n","                    X[item, :, col] + offset,\n","                    label=f\"feature {col+1}\",\n","                )\n","                offset += X[item, :, col].max()\n","            tt = f\"{y[col][0]:0.1f}\"\n","            for t in y[col][1:]:\n","                tt += f\", {t:0.1f}\"\n","            plt.title(f\"EEG_Id = {eeg_ids[item]}\\nTarget = {tt}\", size=14)\n","            plt.legend()\n","            plt.show()\n","        break\n","\n","    del iot, model\n","    gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["# Train Stages"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_score(preds, targets):\n","    oof = pd.DataFrame(preds.copy())\n","    oof[\"id\"] = np.arange(len(oof))\n","    true = pd.DataFrame(targets.copy())\n","    true[\"id\"] = np.arange(len(true))\n","    cv = kaggle_kl_div.score(solution=true, submission=oof, row_id_column_name=\"id\")\n","    return cv\n","\n","\n","def get_result(result_df):\n","    gt = result_df[[\"eeg_id\"] + CFG.target_cols]\n","    gt.sort_values(by=\"eeg_id\", inplace=True)\n","    gt.reset_index(inplace=True, drop=True)\n","    preds = result_df[[\"eeg_id\"] + CFG.pred_cols]\n","    preds.columns = [\"eeg_id\"] + CFG.target_cols\n","    preds.sort_values(by=\"eeg_id\", inplace=True)\n","    preds.reset_index(inplace=True, drop=True)\n","    score_loss = get_score(gt[CFG.target_cols], preds[CFG.target_cols])\n","    LOGGER.info(f\"Score with best loss weights: {score_loss}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T13:42:29.961601Z","iopub.status.busy":"2024-02-20T13:42:29.961176Z","iopub.status.idle":"2024-02-20T14:26:40.159404Z","shell.execute_reply":"2024-02-20T14:26:40.158522Z"},"papermill":{"duration":2650.233098,"end_time":"2024-02-20T14:26:40.161837","exception":false,"start_time":"2024-02-20T13:42:29.928739","status":"completed"},"tags":[]},"outputs":[],"source":["%%time\n","\n","# stageごとにfoldを処理\n","if __name__ == \"__main__\" and CFG.train_by_stages:\n","    seed_torch(seed=CFG.seed)\n","\n","    prev_dir = \"\"\n","    oof_df_all = pd.DataFrame()\n","    oof_stage1 = pd.DataFrame()\n","    oof_stage2 = pd.DataFrame()\n","    for stage in range(len(CFG.total_evaluators)):\n","        pop_dir = f\"{OUTPUT_DIR}pop_{stage+1}_weight_oof/\"\n","        if not os.path.exists(pop_dir):\n","            os.makedirs(pop_dir)\n","\n","        if stage not in CFG.train_stages:\n","            prev_dir = pop_dir\n","            continue\n","\n","        oof_df = pd.DataFrame()\n","        scores = []\n","        for fold in CFG.train_folds:\n","            train_oof_df, score = train_loop(\n","                stage=stage + 1,\n","                epochs=CFG.epochs[stage],\n","                fold=fold,\n","                folds=train_pops[stage],\n","                directory=pop_dir,\n","                prev_dir=prev_dir,\n","                eggs=all_eegs,\n","            )\n","\n","            oof_df = pd.concat([oof_df, train_oof_df])\n","            scores.append(score)\n","\n","            LOGGER.info(f\"========== stage: {stage+1} fold: {fold} result ==========\")\n","            LOGGER.info(f\"Score with best loss weights stage{stage+1}: {score:.4f}\")\n","\n","        LOGGER.info(f\"==================== CV ====================\")\n","        LOGGER.info(f\"Score with best loss weights: {np.mean(scores):.4f}\")\n","\n","        oof_df.reset_index(drop=True, inplace=True)\n","        oof_df.to_csv(\n","            f\"{pop_dir}{CFG.model_name}_oof_df_ver-{CFG.VERSION}_stage-{stage+1}.csv\",\n","            index=False,\n","        )\n","        oof_df_all = pd.concat([oof_df_all, oof_df], axis = 0)\n","        if stage == 0:\n","            oof_stage1 = oof_df\n","        else:\n","            oof_stage2 = oof_df\n","\n","        prev_dir = pop_dir\n","\n","    if CFG.wandb:\n","        wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","\n","# foldごとにstageを処理\n","\n","if __name__ == \"__main__\" and CFG.train_by_folds:\n","    seed_torch(seed=CFG.seed)\n","\n","    stages_scores = {i: [] for i in CFG.train_stages}\n","    stages_oof_df = {i: pd.DataFrame() for i in CFG.train_stages}\n","    oof_df_all = pd.DataFrame()\n","    for fold in CFG.train_folds:\n","\n","        prev_dir = \"\"\n","        for stage in range(len(CFG.total_evaluators)):\n","\n","            pop_dir = f\"{OUTPUT_DIR}pop_{stage+1}_weight_oof/\"\n","            if not os.path.exists(pop_dir):\n","                os.makedirs(pop_dir)\n","\n","            if stage not in CFG.train_stages:\n","                prev_dir = pop_dir\n","                continue\n","\n","            train_oof_df, score = train_loop(\n","                stage=stage + 1,\n","                epochs=CFG.epochs[stage],\n","                fold=fold,\n","                folds=train_pops[stage],\n","                directory=pop_dir,\n","                prev_dir=prev_dir,\n","                eggs=all_eegs,\n","            )\n","\n","            stages_oof_df[stage] = pd.concat([stages_oof_df[stage], train_oof_df])\n","            stages_scores[stage].append(score)\n","\n","            prev_dir = pop_dir\n","\n","            LOGGER.info(f\"========== fold: {fold} stage: {stage+1} result ==========\")\n","            LOGGER.info(f\"Score with best loss weights stage{stage+1}: {score:.4f}\")\n","\n","    for stage, scores in stages_scores.items():\n","        LOGGER.info(f\"============ CV score with best loss weights ============\")\n","        LOGGER.info(f\"Stage {stage}: {np.mean(scores):.4f}\")\n","\n","    for stage, oof_df in stages_oof_df.items():\n","        pop_dir = f\"{OUTPUT_DIR}pop_{stage+1}_weight_oof/\"\n","        oof_df.reset_index(drop=True, inplace=True)\n","        oof_df.to_csv(\n","            f\"{pop_dir}{CFG.model_name}_oof_df_ver-{CFG.VERSION}_stage-{stage+1}.csv\",\n","            index=False,\n","        )\n","        oof_df_all = pd.concat([oof_df_all, oof_df], axis = 0)\n","\n","    if CFG.wandb:\n","        wandb.finish()"]},{"cell_type":"markdown","metadata":{},"source":["# Submission"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# === Pre-process OOF ===\n","gt = oof_stage1[[\"eeg_id\"] + CFG.target_cols]\n","gt.sort_values(by=\"eeg_id\", inplace=True)\n","gt.reset_index(inplace=True, drop=True)\n","\n","preds = oof_stage1[[\"eeg_id\"] + CFG.pred_cols]\n","preds.columns = [\"eeg_id\"] + CFG.target_cols\n","preds.sort_values(by=\"eeg_id\", inplace=True)\n","preds.reset_index(inplace=True, drop=True)\n","\n","y_trues = gt[CFG.target_cols]\n","y_preds = preds[CFG.target_cols]\n","\n","oof = pd.DataFrame(y_preds.copy())\n","oof[\"id\"] = np.arange(len(oof))\n","\n","true = pd.DataFrame(y_trues.copy())\n","true[\"id\"] = np.arange(len(true))\n","\n","cv = kaggle_kl_div.score(solution=true, submission=oof, row_id_column_name=\"id\")\n","print(f\"stage1: CV Score with resnet1D_gru Raw EEG = {cv:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# === Pre-process OOF ===\n","gt = oof_stage2[[\"eeg_id\"] + CFG.target_cols]\n","gt.sort_values(by=\"eeg_id\", inplace=True)\n","gt.reset_index(inplace=True, drop=True)\n","\n","preds = oof_stage2[[\"eeg_id\"] + CFG.pred_cols]\n","preds.columns = [\"eeg_id\"] + CFG.target_cols\n","preds.sort_values(by=\"eeg_id\", inplace=True)\n","preds.reset_index(inplace=True, drop=True)\n","\n","y_trues = gt[CFG.target_cols]\n","y_preds = preds[CFG.target_cols]\n","\n","oof = pd.DataFrame(y_preds.copy())\n","oof[\"id\"] = np.arange(len(oof))\n","\n","true = pd.DataFrame(y_trues.copy())\n","true[\"id\"] = np.arange(len(true))\n","\n","cv = kaggle_kl_div.score(solution=true, submission=oof, row_id_column_name=\"id\")\n","print(f\"stage2: CV Score with resnet1D_gru Raw EEG = {cv:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T15:08:05.806941Z","iopub.status.busy":"2024-02-20T15:08:05.806565Z","iopub.status.idle":"2024-02-20T15:08:05.85807Z","shell.execute_reply":"2024-02-20T15:08:05.857038Z"},"papermill":{"duration":0.167828,"end_time":"2024-02-20T15:08:05.860071","exception":false,"start_time":"2024-02-20T15:08:05.692243","status":"completed"},"tags":[]},"outputs":[],"source":["# === Pre-process OOF ===\n","gt = oof_df_all[[\"eeg_id\"] + CFG.target_cols]\n","gt.sort_values(by=\"eeg_id\", inplace=True)\n","gt.reset_index(inplace=True, drop=True)\n","\n","preds = oof_df_all[[\"eeg_id\"] + CFG.pred_cols]\n","preds.columns = [\"eeg_id\"] + CFG.target_cols\n","preds.sort_values(by=\"eeg_id\", inplace=True)\n","preds.reset_index(inplace=True, drop=True)\n","\n","y_trues = gt[CFG.target_cols]\n","y_preds = preds[CFG.target_cols]\n","\n","oof = pd.DataFrame(y_preds.copy())\n","oof[\"id\"] = np.arange(len(oof))\n","\n","true = pd.DataFrame(y_trues.copy())\n","true[\"id\"] = np.arange(len(true))\n","\n","cv = kaggle_kl_div.score(solution=true, submission=oof, row_id_column_name=\"id\")\n","print(f\"CV Score with resnet1D_gru Raw EEG = {cv:.4f}\")"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":7469972,"sourceId":59093,"sourceType":"competition"},{"datasetId":4297749,"sourceId":7392733,"sourceType":"datasetVersion"},{"datasetId":4317718,"sourceId":7465251,"sourceType":"datasetVersion"},{"datasetId":4378712,"sourceId":7517324,"sourceType":"datasetVersion"}],"dockerImageVersionId":30664,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":5345.179582,"end_time":"2024-02-20T15:08:09.804733","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-20T13:39:04.625151","version":"2.4.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"088fc3f5e4264683bbeaa2d929fab599":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c3d333449fb412dbc86ca31835ef4b0","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3ba5491929cf4cb1bbb8e28514933aa6","value":1}},"11bfd3544cf8411e96cd7ede1451518c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5246ec5881c147f09c90846e9911dda6","placeholder":"​","style":"IPY_MODEL_db8fdfb810194e03b66c7c5e5077ccf5","value":" 1/? [00:00&lt;00:00,  1.37it/s]"}},"2c3d333449fb412dbc86ca31835ef4b0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"3ba5491929cf4cb1bbb8e28514933aa6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5246ec5881c147f09c90846e9911dda6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58eb07f979fd49e8a9155ad60c77923c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"993085d825a542b1b5c44cd42f7f8c89":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c818523154ec45689615162b4c03bf96","IPY_MODEL_088fc3f5e4264683bbeaa2d929fab599","IPY_MODEL_11bfd3544cf8411e96cd7ede1451518c"],"layout":"IPY_MODEL_fa70a85db4944741a7d7b13cef19bb70"}},"c818523154ec45689615162b4c03bf96":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58eb07f979fd49e8a9155ad60c77923c","placeholder":"​","style":"IPY_MODEL_ea4dcc5f4fcf4011a7ba7dc587109a9b","value":""}},"db8fdfb810194e03b66c7c5e5077ccf5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea4dcc5f4fcf4011a7ba7dc587109a9b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fa70a85db4944741a7d7b13cef19bb70":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}},"version_major":2,"version_minor":0}}},"nbformat":4,"nbformat_minor":4}
